{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6cfeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import re\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from eval import get_run_metrics, read_run_dir, get_model_from_run\n",
    "from plot_utils import basic_plot, collect_results, relevant_model_names\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set_theme('notebook', 'darkgrid')\n",
    "palette = sns.color_palette('colorblind')\n",
    "\n",
    "run_dir = \"../models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d018b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = read_run_dir(run_dir)\n",
    "df  # list all the runs in our run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9980951",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"linear_regression\"\n",
    "#task = \"sparse_linear_regression\"\n",
    "# task = \"decision_tree\"\n",
    "#task = \"relu_2nn_regression\"\n",
    "\n",
    "run_id = \"toy_w1_1\"  # if you train more models, replace with the run_id from the table above\n",
    "\n",
    "run_path = os.path.join(run_dir, task, run_id)\n",
    "recompute_metrics = False\n",
    "\n",
    "if recompute_metrics:\n",
    "    get_run_metrics(run_path)  # these are normally precomputed at the end of training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d09964",
   "metadata": {},
   "source": [
    "# Plot pre-computed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8e02c5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def valid_row(r):\n",
    "    return r.task == task and r.run_id == run_id\n",
    "\n",
    "metrics = collect_results(run_dir, df, valid_row=valid_row)\n",
    "_, conf = get_model_from_run(run_path, only_conf=True)\n",
    "n_dims = conf.model.n_dims\n",
    "\n",
    "models = relevant_model_names[task]\n",
    "basic_plot(metrics[\"standard\"], models=models)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f961d4",
   "metadata": {},
   "source": [
    "# Interactive setup\n",
    "\n",
    "We will now directly load the model and measure its in-context learning ability on a batch of random inputs. (In the paper we average over multiple such batches to obtain better estimates.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb327ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from samplers import get_data_sampler\n",
    "from tasks import get_task_sampler\n",
    "print(conf.training.curriculum.points.end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f45232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, conf = get_model_from_run(run_path)\n",
    "\n",
    "n_dims = conf.model.n_dims\n",
    "batch_size = conf.training.batch_size\n",
    "data_sampler = get_data_sampler(conf.training.data, n_dims)\n",
    "task_sampler = get_task_sampler(\n",
    "    conf.training.task,\n",
    "    n_dims,\n",
    "    batch_size,\n",
    "    **conf.training.task_kwargs\n",
    ")\n",
    "\n",
    "task = task_sampler()\n",
    "xs = data_sampler.sample_xs(b_size=batch_size, n_points=conf.training.curriculum.points.end)\n",
    "ys = task.evaluate(xs)\n",
    "with torch.no_grad():\n",
    "    pred = model(xs, ys)\n",
    "metric = task.get_metric()\n",
    "loss = metric(pred, ys).numpy()\n",
    "\n",
    "sparsity = conf.training.task_kwargs.sparsity if \"sparsity\" in conf.training.task_kwargs else None\n",
    "baseline = {\n",
    "    \"linear_regression\": n_dims,\n",
    "    \"sparse_linear_regression\": sparsity,\n",
    "    \"relu_2nn_regression\": n_dims,\n",
    "    \"decision_tree\": 1,\n",
    "}[conf.training.task]\n",
    "\n",
    "plt.plot(loss.mean(axis=0), lw=2, label=\"Transformer\")\n",
    "plt.axhline(baseline, ls=\"--\", color=\"gray\", label=\"zero estimator\")\n",
    "plt.xlabel(\"# in-context examples\")\n",
    "plt.ylabel(\"squared error\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4b2c07",
   "metadata": {},
   "source": [
    "### 4.1 Sample Selection / Covariate Shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b1666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_Square_Error(ys, pred):\n",
    "    # Step 2: Calculate the mean of the actual outcomes\n",
    "    y_mean = torch.mean(ys)\n",
    "\n",
    "    # Step 3: Compute SS_tot and SS_res\n",
    "    SS_tot = torch.sum((ys - y_mean) ** 2)\n",
    "    SS_res = torch.sum((ys - pred) ** 2)\n",
    "\n",
    "    # Step 4: Calculate R^2\n",
    "    R_square = 1 - SS_res / SS_tot\n",
    "    return R_square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa18dd9",
   "metadata": {},
   "source": [
    "####  Part 1 - Sample Selection: W1 = 1, w2 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "70ddc961",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m ys_list\u001b[38;5;241m.\u001b[39mappend(ys)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 19\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(prompt_length):\n\u001b[1;32m     21\u001b[0m     actual_points_w_1[j]\u001b[38;5;241m.\u001b[39mextend(ys[:, j])\n",
      "File \u001b[0;32m~/anaconda3/envs/in-context-learning/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/in-context-learning-fork/src/models.py:171\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[0;34m(self, xs, ys, inds)\u001b[0m\n\u001b[1;32m    169\u001b[0m zs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine(xs, ys)\n\u001b[1;32m    170\u001b[0m embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_in(zs)\n\u001b[0;32m--> 171\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeds\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mlast_hidden_state\n\u001b[1;32m    172\u001b[0m prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_out(output)\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m prediction[:, ::\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m][:, inds]\n",
      "File \u001b[0;32m~/anaconda3/envs/in-context-learning/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/in-context-learning/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:890\u001b[0m, in \u001b[0;36mGPT2Model.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    880\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    881\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    882\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    887\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    888\u001b[0m     )\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 890\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    901\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/in-context-learning/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/in-context-learning/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:395\u001b[0m, in \u001b[0;36mGPT2Block.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    393\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    394\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln_1(hidden_states)\n\u001b[0;32m--> 395\u001b[0m attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    403\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n\u001b[1;32m    404\u001b[0m outputs \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m1\u001b[39m:]\n",
      "File \u001b[0;32m~/anaconda3/envs/in-context-learning/lib/python3.8/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/in-context-learning/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:336\u001b[0m, in \u001b[0;36mGPT2Attention.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    334\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_upcast_and_reordered_attn(query, key, value, attention_mask, head_mask)\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 336\u001b[0m     attn_output, attn_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_heads(attn_output, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\n\u001b[1;32m    339\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mc_proj(attn_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/in-context-learning/lib/python3.8/site-packages/transformers/models/gpt2/modeling_gpt2.py:193\u001b[0m, in \u001b[0;36mGPT2Attention._attn\u001b[0;34m(self, query, key, value, attention_mask, head_mask)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_attn\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, key, value, attention_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, head_mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 193\u001b[0m     attn_weights \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmatmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_attn_weights:\n\u001b[1;32m    196\u001b[0m         attn_weights \u001b[38;5;241m=\u001b[39m attn_weights \u001b[38;5;241m/\u001b[39m (value\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_batches = 50\n",
    "prompt_length = 2*conf.training.curriculum.points.end-1\n",
    "# # save xs and ys for the 4.2 experiment\n",
    "xs_list = [] \n",
    "ys_list = [] \n",
    "actual_points_w_1 = [[] for _ in range(prompt_length)]\n",
    "predicted_points_w_1 = [[] for _ in range(prompt_length)]\n",
    "# Generate data and perform the experiment\n",
    "for _ in tqdm(range(n_batches)):\n",
    "\n",
    "    xs = data_sampler.sample_xs(b_size=batch_size, n_points=prompt_length)\n",
    "    # 64 x 101 x 20\n",
    "    xs_list.append(xs)\n",
    "    ys = task.evaluate(xs)\n",
    "    # 64 x 101\n",
    "    ys_list.append(ys)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(xs, ys)\n",
    "    for j in range(prompt_length):\n",
    "        actual_points_w_1[j].extend(ys[:, j])\n",
    "        predicted_points_w_1[j].extend(pred[:, j])\n",
    "\n",
    "R_square_values_w_1 = []\n",
    "\n",
    "for point_idx in range(prompt_length):\n",
    "    actual = torch.tensor(actual_points_w_1[point_idx])\n",
    "    predicted = torch.tensor(predicted_points_w_1[point_idx])\n",
    "    R_square = R_Square_Error(actual, predicted)\n",
    "    R_square_values_w_1.append(R_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea9f8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_length = 2*conf.training.curriculum.points.end-1\n",
    "print(prompt_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524d2100",
   "metadata": {},
   "source": [
    "####  Part 2 - Covariate Shifts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eaa555",
   "metadata": {},
   "source": [
    "##### W1 = 0.9, w2 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242ca6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_points_w_9 = [[] for _ in range(prompt_length)]\n",
    "predicted_points_w_9 = [[] for _ in range(prompt_length)]\n",
    "# xs_list_w_9 = [] \n",
    "# ys_list_w_8 = [] \n",
    "for _ in tqdm(range(n_batches)):\n",
    "    xs = data_sampler.sample_xs(b_size=batch_size, n_points=prompt_length, w1=0.9, w2=0.1)\n",
    "    # xs_list_w_8.append(xs)\n",
    "    ys = task.evaluate(xs)\n",
    "    # ys_list_w_8.append(ys)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(xs, ys)\n",
    "    for j in range(prompt_length):\n",
    "        actual_points_w_9[j].extend(ys[:, j])\n",
    "        predicted_points_w_9[j].extend(pred[:, j])\n",
    "        \n",
    "R_square_values_w_9 = []\n",
    "\n",
    "for point_idx in range(prompt_length):\n",
    "    actual = torch.tensor(actual_points_w_9[point_idx])\n",
    "    predicted = torch.tensor(predicted_points_w_9[point_idx])\n",
    "    R_square = R_Square_Error(actual, predicted)\n",
    "    R_square_values_w_9.append(R_square)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8a08b6",
   "metadata": {},
   "source": [
    "##### W1 = 0.7, w2 = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_points_w_7 = [[] for _ in range(prompt_length)]\n",
    "predicted_points_w_7 = [[] for _ in range(prompt_length)]\n",
    "# Generate data and perform the experiment\n",
    "# xs_list_w_0 = [] \n",
    "# ys_list_w_0 = [] \n",
    "for _ in tqdm(range(n_batches)):\n",
    "    xs = data_sampler.sample_xs(b_size=batch_size, n_points=prompt_length, w1=0.7, w2=0.3)\n",
    "    # xs_list_w_0.append(xs)\n",
    "    ys = task.evaluate(xs)\n",
    "    # ys_list_w_0.append(ys)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(xs, ys)\n",
    "    for j in range(prompt_length):\n",
    "        actual_points_w_7[j].extend(ys[:, j])\n",
    "        predicted_points_w_7[j].extend(pred[:, j])\n",
    "        \n",
    "\n",
    "R_square_values_w_7 = []\n",
    "\n",
    "for point_idx in range(prompt_length):\n",
    "    actual = torch.tensor(actual_points_w_7[point_idx])\n",
    "    predicted = torch.tensor(predicted_points_w_7[point_idx])\n",
    "    R_square = R_Square_Error(actual, predicted)\n",
    "    R_square_values_w_7.append(R_square)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d359918c",
   "metadata": {},
   "source": [
    "##### W1 = 0.5, w2 = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a8d8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_points_w_5 = [[] for _ in range(prompt_length)]\n",
    "predicted_points_w_5 = [[] for _ in range(prompt_length)]\n",
    "# xs_list_w_1 = [] \n",
    "# ys_list_w_1 = [] \n",
    "all_errors_w1_5 = []\n",
    "for _ in tqdm(range(n_batches)):\n",
    "    xs = data_sampler.sample_xs(b_size=batch_size, n_points=prompt_length, w1=0.5, w2=0.5)\n",
    "    # xs_list_w_1.append(xs)\n",
    "    ys = task.evaluate(xs)\n",
    "    # ys_list_w_1.append(ys)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(xs, ys)\n",
    "    for j in range(prompt_length):\n",
    "        actual_points_w_5[j].extend(ys[:, j])\n",
    "        predicted_points_w_5[j].extend(pred[:, j])\n",
    "        \n",
    "\n",
    "R_square_values_w_5 = []\n",
    "\n",
    "for point_idx in range(prompt_length):\n",
    "    actual = torch.tensor(actual_points_w_5[point_idx])\n",
    "    predicted = torch.tensor(predicted_points_w_5[point_idx])\n",
    "    R_square = R_Square_Error(actual, predicted)\n",
    "    R_square_values_w_5.append(R_square)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1e86f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 5), facecolor='none')\n",
    "plt.plot(range(prompt_length), R_square_values_w_1, label='w1=1, w2=0', color='darkred', linewidth=2)\n",
    "plt.plot(range(prompt_length), R_square_values_w_9, label='w1=0.9, w2=0.1', color='blue', linewidth=2)\n",
    "plt.plot(range(prompt_length), R_square_values_w_7, label='w1=0.7, w2=0.3', linewidth=2)\n",
    "plt.plot(range(prompt_length), R_square_values_w_5, label='w1=0.5, w2=0.5', linewidth=2)\n",
    "\n",
    "plt.axhline(1, ls=\"--\", color=\"darkgray\", label=\"Baseline\")\n",
    "plt.axvline(x=(prompt_length-1)/2, color='grey', linestyle='--')  # Grey vertical line\n",
    "# Adding legend, labels, and title\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.xlabel('In-context Examples')\n",
    "plt.ylabel('Mean Squared Errors')\n",
    "plt.title('Comparison of RSE with Different w1 and w2')\n",
    "\n",
    "plt.grid(color='lightgray', linestyle='-', linewidth=0.5)\n",
    "# plt.savefig(\"../output/4.1_test_3_Sample_Selection_Covariate_Shifts.pdf\", bbox_inches='tight', transparent=True)\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15de2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f9bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_array = np.array(xs_list_w_9)\n",
    "# y_array = np.array(ys_list_w_9)\n",
    "# print(\"Shape of the first element in X_array:\", X_array[0].shape)\n",
    "# print(\"Shape of y_array:\", y_array.shape)\n",
    "# X_reshaped_list = [x_tensor.numpy().reshape(-1, 101*20) for x_tensor in X_array]\n",
    "# y_reshaped_list = [y_tensor.numpy().reshape(-1, 101) for y_tensor in y_array]\n",
    "# X_reshaped = np.concatenate(X_reshaped_list, axis=0)\n",
    "# y_reshaped = np.concatenate(y_reshaped_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e5c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Splitting dataset into training and testing set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_reshaped, test_size=0.5, random_state=42)\n",
    "\n",
    "# # Creating Linear Regression model\n",
    "# sklearn_linear_model = LinearRegression()\n",
    "\n",
    "# # Training the model\n",
    "# sklearn_linear_model.fit(X_train, y_train)\n",
    "\n",
    "# # Making predictions\n",
    "# y_pred = sklearn_linear_model.predict(X_test)\n",
    "\n",
    "# # Evaluating the model\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62946b1a",
   "metadata": {},
   "source": [
    "#### 4.2 Sensitivity to Label Format: second part <strong>Linear regression with random labels<strong>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827e64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "actual_points_random = [[] for _ in range(prompt_length)]\n",
    "predicted_points_random = [[] for _ in range(prompt_length)]\n",
    "\n",
    "# Generate data and perform the experiment\n",
    "for batch_idx in tqdm(range(50)):\n",
    "    xs = xs_list[batch_idx]\n",
    "    ys = ys_list[batch_idx]\n",
    "\n",
    "    # j's idx starts at 1, but in graph, we refer it to 0\n",
    "    for j in range(1, prompt_length+1):\n",
    "        permuted_ys = np.copy(ys)\n",
    "        if j > 2:  # if j == 1, 2, there are no prior labels or no need to permuted\n",
    "            for i in range(batch_size):\n",
    "                np.random.shuffle(permuted_ys[i, :j-1])\n",
    "    \n",
    "    # Transfer np array to tensor\n",
    "    permuted_ys_tensor = torch.from_numpy(permuted_ys)\n",
    "    # predict with the si\n",
    "    with torch.no_grad():\n",
    "        pred = model(xs, permuted_ys_tensor)\n",
    "    \n",
    "    for j in range(prompt_length):\n",
    "        actual_points_random[j].extend(ys[:, j])\n",
    "        predicted_points_random[j].extend(pred[:, j])\n",
    "\n",
    "R_square_values_w_random = []\n",
    "\n",
    "for point_idx in range(prompt_length):\n",
    "    actual = torch.tensor(actual_points_random[point_idx])\n",
    "    predicted = torch.tensor(predicted_points_random[point_idx])\n",
    "    R_square = R_Square_Error(actual, predicted)\n",
    "    R_square_values_w_random.append(R_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e37fa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_errors_random_labels = np.mean(all_errors_random_labels, axis=(0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eaa4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(range(prompt_length), R_square_values_w_1, label=\"True Labels\",color='darkred', linewidth=2)\n",
    "plt.plot(range(prompt_length), R_square_values_w_random, label=\"Random Labels\", linewidth=2)\n",
    "plt.axhline(1, ls=\"--\", color=\"darkgray\", label=\"Baseline\", linewidth=2)\n",
    "# existing_ticks = plt.xticks()[0]\n",
    "# new_ticks = sorted(set(existing_ticks).union({10}))\n",
    "# plt.xticks(new_ticks)\n",
    "plt.legend()\n",
    "plt.xlabel('In-context Examples')\n",
    "plt.ylabel('Mean Squared Errors')\n",
    "plt.title('MSE with Random Labels for Each In-context Examples')\n",
    "plt.grid(color='lightgray', linestyle='-', linewidth=0.5)\n",
    "# plt.savefig(\"../output/4.2_Std_Sensitivity_to_Label_Format.pdf\", bbox_inches = \"tight\", transparent=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
