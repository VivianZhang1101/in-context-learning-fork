{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6cfeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "import re\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "os.chdir(parent_directory)\n",
    "\n",
    "from eval import get_run_metrics, read_run_dir, get_model_from_run\n",
    "from plot_utils import basic_plot, collect_results, relevant_model_names\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set_theme('notebook', 'darkgrid')\n",
    "palette = sns.color_palette('colorblind')\n",
    "# Enable latex in plot\n",
    "# matplotlib.rcParams['text.usetex'] = True\n",
    "\n",
    "run_dir = \"../models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8d018b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>task</th>\n",
       "      <th>model</th>\n",
       "      <th>kwargs</th>\n",
       "      <th>num_tasks</th>\n",
       "      <th>num_examples</th>\n",
       "      <th>n_dims</th>\n",
       "      <th>n_layer</th>\n",
       "      <th>n_head</th>\n",
       "      <th>run_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pretrained_complete</td>\n",
       "      <td>linear_regression</td>\n",
       "      <td>Transformer</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>fix_linear_regression_standard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                run_id               task        model kwargs  num_tasks  \\\n",
       "0  pretrained_complete  linear_regression  Transformer                -1   \n",
       "\n",
       "   num_examples  n_dims  n_layer  n_head                        run_name  \n",
       "0            -1      20       12       8  fix_linear_regression_standard  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = read_run_dir(run_dir)\n",
    "df  # list all the runs in our run_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9980951",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"linear_regression\"\n",
    "\n",
    "run_id = \"pretrained_complete\"  # if you train more models, replace with the run_id from the table above\n",
    "\n",
    "run_path = os.path.join(run_dir, task, run_id)\n",
    "recompute_metrics = False\n",
    "\n",
    "if recompute_metrics:\n",
    "    get_run_metrics(run_path)  # these are normally precomputed at the end of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beb327ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from samplers import get_data_sampler\n",
    "from tasks import get_task_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f45232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, conf = get_model_from_run(run_path)\n",
    "\n",
    "n_dims = conf.model.n_dims\n",
    "batch_size = conf.training.batch_size\n",
    "data_sampler = get_data_sampler(conf.training.data, n_dims)\n",
    "task_sampler = get_task_sampler(\n",
    "    conf.training.task,\n",
    "    n_dims,\n",
    "    batch_size,\n",
    "    **conf.training.task_kwargs\n",
    ")\n",
    "\n",
    "task = task_sampler()\n",
    "metric = task.get_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4afd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_Square_Error(ys, pred):\n",
    "    y_mean = torch.mean(ys)\n",
    "\n",
    "    SS_tot = torch.sum((ys - y_mean) ** 2)\n",
    "    SS_res = torch.sum((ys - pred) ** 2)\n",
    "\n",
    "    R_square = 1 - SS_res / SS_tot\n",
    "    return R_square"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4b2c07",
   "metadata": {},
   "source": [
    "### Experiment 3 - Retrieving Similar Samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa18dd9",
   "metadata": {},
   "source": [
    "####  Part 1 - Linear regression with best prompts -- COS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70ddc961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.005004167556762695,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "362b1dd865a44f72825fdc0720f65d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sampling 1000\n",
    "n_pairs = 1000\n",
    "n_dims = conf.model.n_dims\n",
    "batch_size = conf.training.batch_size # this is 64\n",
    "# n_batches = 100\n",
    "n_batches = 1 # We use n_batches = 1 here to speed up the experiment speed. We used n_batches = 100 for the experiment result in the paper\n",
    "prompt_length = 76\n",
    "\n",
    "# compute similarity\n",
    "def similarity(x, x_test):\n",
    "    cos = torch.nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    x = x.unsqueeze(0)\n",
    "    x_test = x_test.unsqueeze(0)\n",
    "    return cos(x, x_test)\n",
    "\n",
    "# record the xs for later experiment\n",
    "xs_list = []\n",
    "ys_list = []\n",
    "\n",
    "actual_points_worst_prompt = [[] for _ in range(prompt_length)]\n",
    "predicted_points_worst_prompt = [[] for _ in range(prompt_length)]\n",
    "for batch_idx in tqdm(range(n_batches)):\n",
    "    # Sample 1101 points\n",
    "    xs = data_sampler.sample_xs(b_size=batch_size, n_points=n_pairs+prompt_length)\n",
    "    xs_list.append(xs)\n",
    "    ys= task.evaluate(xs)\n",
    "    ys_list.append(ys)\n",
    "    batch_errors = []\n",
    "    for j in range(1, prompt_length+1):\n",
    "        prompt_xs = np.zeros((batch_size, prompt_length, n_dims))\n",
    "        prompt_ys = np.zeros((batch_size, prompt_length))\n",
    "        for batch_idx in range(batch_size):\n",
    "            # test sample\n",
    "            x_test, y_test = xs[batch_idx, -j, :], ys[batch_idx, -j]\n",
    "            sims = torch.tensor([similarity(xs[batch_idx, i, :], x_test) for i in range(n_pairs)])\n",
    "            selected_indices = torch.topk(sims, j-1, largest=False).indices\n",
    "            prompt_xs[batch_idx, :j-1, :] = xs[batch_idx, selected_indices, :]\n",
    "            prompt_ys[batch_idx, :j-1] = ys[batch_idx, selected_indices]\n",
    "            prompt_xs[batch_idx, j-1, :] = x_test\n",
    "            prompt_ys[batch_idx, j-1] = y_test\n",
    "            \n",
    "        prompt_xs = torch.from_numpy(prompt_xs).float()\n",
    "        prompt_ys = torch.from_numpy(prompt_ys).float()\n",
    "        with torch.no_grad():\n",
    "            pred = model(prompt_xs, prompt_ys)\n",
    "            \n",
    "        actual_points_worst_prompt[j-1].extend(prompt_ys[:, j-1])\n",
    "        predicted_points_worst_prompt[j-1].extend(pred[:, j-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f65456",
   "metadata": {},
   "outputs": [],
   "source": [
    "worst = []\n",
    "\n",
    "for point_idx in range(prompt_length):\n",
    "    actual = torch.tensor(actual_points_worst_prompt[point_idx])\n",
    "    predicted = torch.tensor(predicted_points_worst_prompt[point_idx])\n",
    "    R_square = R_Square_Error(actual, predicted)\n",
    "    worst.append(R_square)\n",
    "\n",
    "\n",
    "with open('./data/exp_3_worst.txt', 'w') as f:\n",
    "    for value in worst:\n",
    "        f.write(f\"{value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec61a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.004678249359130859,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 1,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4a2e7867294dfb8a13bfbbdd5f7c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "actual_points_best_prompt = [[] for _ in range(prompt_length)]\n",
    "predicted_points_best_prompt = [[] for _ in range(prompt_length)]\n",
    "for batch_idx in tqdm(range(n_batches)):\n",
    "    xs = xs_list[batch_idx]\n",
    "    ys = ys_list[batch_idx]\n",
    "    for j in range(1, prompt_length+1):\n",
    "        prompt_xs = np.zeros((batch_size, prompt_length, n_dims))\n",
    "        prompt_ys = np.zeros((batch_size, prompt_length))\n",
    "        for batch_idx in range(batch_size):\n",
    "            # test sample\n",
    "            x_test, y_test = xs[batch_idx, -j, :], ys[batch_idx, -j]\n",
    "            sims = torch.tensor([similarity(xs[batch_idx, i, :], x_test) for i in range(n_pairs)])\n",
    "            selected_indices = torch.topk(sims, j-1, largest=True).indices\n",
    "            prompt_xs[batch_idx, :j-1, :] = xs[batch_idx, selected_indices, :]\n",
    "            prompt_ys[batch_idx, :j-1] = ys[batch_idx, selected_indices]\n",
    "            prompt_xs[batch_idx, j-1, :] = x_test\n",
    "            prompt_ys[batch_idx, j-1] = y_test\n",
    "            \n",
    "        prompt_xs = torch.from_numpy(prompt_xs).float()\n",
    "        prompt_ys = torch.from_numpy(prompt_ys).float()\n",
    "        with torch.no_grad():\n",
    "            pred = model(prompt_xs, prompt_ys)\n",
    "            \n",
    "        actual_points_best_prompt[j-1].extend(prompt_ys[:, j-1])\n",
    "        predicted_points_best_prompt[j-1].extend(pred[:, j-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c610d839",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = []\n",
    "\n",
    "for point_idx in range(prompt_length):\n",
    "    actual = torch.tensor(actual_points_best_prompt[point_idx])\n",
    "    predicted = torch.tensor(predicted_points_best_prompt[point_idx])\n",
    "    R_square = R_Square_Error(actual, predicted)\n",
    "    best.append(R_square)\n",
    "    \n",
    "\n",
    "with open('./data/exp_3_best.txt', 'w') as f:\n",
    "    for value in best:\n",
    "        f.write(f\"{value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe33044",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/base_line.txt', 'r') as file:\n",
    "    base_line = [float(line.strip()) for line in file]\n",
    "with open('./data/exp_1_w_1.txt', 'r') as file:\n",
    "    w_1 = [float(line.strip()) for line in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228802d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_length = 76\n",
    "plt.figure(figsize=(10, 5), facecolor='none')\n",
    "plt.plot(range(prompt_length), best, label=\"High Similarity\", linewidth=3, color=\"darkred\")\n",
    "plt.plot(range(prompt_length), w_1, label=\"Normal Similarity\", linewidth=3)\n",
    "plt.plot(range(prompt_length), worst, label=\"Low Similarity\", linewidth=3)\n",
    "plt.plot(range(prompt_length), base_line, label=\"Least Squares\", linewidth=3, color=\"grey\")\n",
    "x = [0, 25, 50, 75]\n",
    "plt.xticks(x, fontsize=28)\n",
    "plt.yticks(fontsize=28)\n",
    "plt.axhline(1, ls=\"--\", color=\"darkgrey\")\n",
    "plt.axvline(x=50, color='darkgrey', linestyle='--')  # Grey vertical line\n",
    "plt.legend(loc='lower right', fontsize=17)\n",
    "plt.xlabel('In-context Examples', fontsize=28)\n",
    "plt.ylabel('R-Squared', fontsize=28)\n",
    "plt.grid(color='lightgray', linestyle='-', linewidth=0.5)\n",
    "# save fig\n",
    "# plt.savefig(\"../pretrain_complete/test_4_3.pdf\", bbox_inches = \"tight\", transparent=True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
